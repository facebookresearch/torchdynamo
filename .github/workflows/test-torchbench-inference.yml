name: Test TorchBenchmark Inference
on:
  push:
    branches:
      - main
  pull_request:

jobs:
  test-torchbench-inference:
    defaults:
      run:
        shell: bash -l {0}
    runs-on: linux.4xlarge.nvidia.gpu
    steps:
    - uses: actions/checkout@v2
    - uses: conda-incubator/setup-miniconda@v2
      with:
        auto-update-conda: true
        python-version: 3.9
        activate-environment: build
        miniconda-version: py39_4.12.0
    - run: make setup_nightly_gpu
    - run: make develop
    - uses: actions/checkout@v2
      with:
        repository: pytorch/benchmark
        path: torchbenchmark
    - name: Install torchbench
      run: cd torchbenchmark && python install.py
    - name: Run torchbench inference
      run: |
        python benchmarks/torchbench.py --ci --quiet -d cuda --inductor --float32 \
        --raise-on-assertion-error --raise-on-backend-error \
        -x Super_SloMo -x moco -x dlrm -x fambench_dlrm -x fastNLP_Bert -x hf_Reformer -x tacotron2 \
        -x pyhpc_ -x yolov3 \
        --output=inductor_torchbench_inference.csv
    - uses: actions/upload-artifact@v2
      with:
        name: TorchBenchmark Inference Result
        path: inductor_torchbench_inference.csv
    - run: python .github/check_csv.py -f inductor_torchbench_inference.csv

concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.sha }}
  cancel-in-progress: true
